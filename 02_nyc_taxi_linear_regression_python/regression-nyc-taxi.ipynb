{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/regression-part2-automated-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Use machine learning to predict taxi fares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you use  machine learning in Azure Machine Learning service to create a regression model to predict NYC taxi fare prices.\n",
    "In this tutorial you learn the following tasks:\n",
    "\n",
    "* Download, transform, and clean data using Azure Open Datasets\n",
    "* Train an automated machine learning regression model\n",
    "* Calculate model accuracy\n",
    "\n",
    "If you donâ€™t have an Azure subscription, create a free account before you begin. Try the [free or paid version](https://aka.ms/AMLFree) of Azure Machine Learning service today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete the [setup tutorial](https://docs.microsoft.com/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup) if you don't already have an Azure Machine Learning service workspace or notebook virtual machine.\n",
    "* After you complete the setup tutorial, open the **tutorials/regression-automated-ml.ipynb** notebook using the same notebook server.\n",
    "\n",
    "This tutorial is also available on [GitHub](https://github.com/Azure/MachineLearningNotebooks/tree/master/tutorials) if you wish to run it in your own [local environment](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/README.md#setup-using-a-local-conda-environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages. The Open Datasets package contains a class representing each data source (`NycTlcGreen` for example) to easily filter date parameters before downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"memasanz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azureml.core import Dataset\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by creating a dataframe to hold the taxi data. Then preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>lpepPickupDatetime</th>\n",
       "      <th>lpepDropoffDatetime</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>puLocationId</th>\n",
       "      <th>doLocationId</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>...</th>\n",
       "      <th>fareAmount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mtaTax</th>\n",
       "      <th>improvementSurcharge</th>\n",
       "      <th>tipAmount</th>\n",
       "      <th>tollsAmount</th>\n",
       "      <th>ehailFee</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>tripType</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "      <td>2015-01-30 19:01:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.996155</td>\n",
       "      <td>40.690903</td>\n",
       "      <td>-73.964287</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "      <td>2015-01-17 23:35:16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.687984</td>\n",
       "      <td>-73.955116</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "      <td>2015-01-16 01:52:55</td>\n",
       "      <td>1</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.957787</td>\n",
       "      <td>40.721779</td>\n",
       "      <td>-73.963005</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "      <td>2015-01-04 17:16:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.919914</td>\n",
       "      <td>40.826023</td>\n",
       "      <td>-73.904839</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "      <td>2015-01-14 10:33:30</td>\n",
       "      <td>1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.943710</td>\n",
       "      <td>40.825439</td>\n",
       "      <td>-73.982964</td>\n",
       "      <td>...</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-19 18:10:41</td>\n",
       "      <td>2015-01-19 18:32:20</td>\n",
       "      <td>1</td>\n",
       "      <td>7.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.940918</td>\n",
       "      <td>40.839714</td>\n",
       "      <td>-73.994339</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-19 18:10:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01 15:44:21</td>\n",
       "      <td>2015-01-01 15:50:16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985718</td>\n",
       "      <td>40.685646</td>\n",
       "      <td>-73.996773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-01 15:44:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-12 08:01:21</td>\n",
       "      <td>2015-01-12 08:14:52</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.939865</td>\n",
       "      <td>40.789822</td>\n",
       "      <td>-73.952957</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-12 08:01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-16 21:54:26</td>\n",
       "      <td>2015-01-16 22:12:39</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.957939</td>\n",
       "      <td>40.721928</td>\n",
       "      <td>-73.926247</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-16 21:54:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06 06:34:53</td>\n",
       "      <td>2015-01-06 06:44:23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.943825</td>\n",
       "      <td>40.810257</td>\n",
       "      <td>-73.943062</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-06 06:34:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorID  lpepPickupDatetime lpepDropoffDatetime  passengerCount  \\\n",
       "0         2 2015-01-30 18:38:09 2015-01-30 19:01:49               1   \n",
       "1         1 2015-01-17 23:21:39 2015-01-17 23:35:16               1   \n",
       "2         2 2015-01-16 01:38:40 2015-01-16 01:52:55               1   \n",
       "3         2 2015-01-04 17:09:26 2015-01-04 17:16:12               1   \n",
       "4         1 2015-01-14 10:10:57 2015-01-14 10:33:30               1   \n",
       "5         2 2015-01-19 18:10:41 2015-01-19 18:32:20               1   \n",
       "6         2 2015-01-01 15:44:21 2015-01-01 15:50:16               1   \n",
       "7         2 2015-01-12 08:01:21 2015-01-12 08:14:52               5   \n",
       "8         1 2015-01-16 21:54:26 2015-01-16 22:12:39               1   \n",
       "9         2 2015-01-06 06:34:53 2015-01-06 06:44:23               1   \n",
       "\n",
       "   tripDistance  puLocationId  doLocationId  pickupLongitude  pickupLatitude  \\\n",
       "0          1.88           NaN           NaN       -73.996155       40.690903   \n",
       "1          2.70           NaN           NaN       -73.978508       40.687984   \n",
       "2          3.54           NaN           NaN       -73.957787       40.721779   \n",
       "3          1.00           NaN           NaN       -73.919914       40.826023   \n",
       "4          5.10           NaN           NaN       -73.943710       40.825439   \n",
       "5          7.41           NaN           NaN       -73.940918       40.839714   \n",
       "6          1.03           NaN           NaN       -73.985718       40.685646   \n",
       "7          2.94           NaN           NaN       -73.939865       40.789822   \n",
       "8          3.00           NaN           NaN       -73.957939       40.721928   \n",
       "9          2.31           NaN           NaN       -73.943825       40.810257   \n",
       "\n",
       "   dropoffLongitude  ...  fareAmount  extra mtaTax  improvementSurcharge  \\\n",
       "0        -73.964287  ...        15.0    1.0    0.5                   0.3   \n",
       "1        -73.955116  ...        11.5    0.5    0.5                   0.3   \n",
       "2        -73.963005  ...        13.5    0.5    0.5                   0.3   \n",
       "3        -73.904839  ...         6.5    0.0    0.5                   0.3   \n",
       "4        -73.982964  ...        18.5    0.0    0.5                   0.3   \n",
       "5        -73.994339  ...        24.0    0.0    0.5                   0.3   \n",
       "6        -73.996773  ...         6.5    0.0    0.5                   0.3   \n",
       "7        -73.952957  ...        12.5    0.0    0.5                   0.3   \n",
       "8        -73.926247  ...        14.0    0.5    0.5                   0.3   \n",
       "9        -73.943062  ...        10.0    0.0    0.5                   0.3   \n",
       "\n",
       "   tipAmount  tollsAmount  ehailFee totalAmount  tripType   __index_level_0__  \n",
       "0       4.00          0.0       NaN       20.80       1.0 2015-01-30 18:38:09  \n",
       "1       2.55          0.0       NaN       15.35       1.0 2015-01-17 23:21:39  \n",
       "2       2.80          0.0       NaN       17.60       1.0 2015-01-16 01:38:40  \n",
       "3       0.00          0.0       NaN        7.30       1.0 2015-01-04 17:09:26  \n",
       "4       3.85          0.0       NaN       23.15       1.0 2015-01-14 10:10:57  \n",
       "5       4.80          0.0       NaN       29.60       1.0 2015-01-19 18:10:41  \n",
       "6       1.30          0.0       NaN        8.60       1.0 2015-01-01 15:44:21  \n",
       "7       0.00          0.0       NaN       13.30       1.0 2015-01-12 08:01:21  \n",
       "8       2.00          0.0       NaN       17.30       1.0 2015-01-16 21:54:26  \n",
       "9       2.00          0.0       NaN       12.80       1.0 2015-01-06 06:34:53  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_taxi_dataset = Dataset.Tabular.from_parquet_files(path=\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/green_taxi_data.parquet\")\n",
    "green_taxi_df = green_taxi_dataset.to_pandas_dataframe()\n",
    "green_taxi_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the initial data is loaded, define a function to create various time-based features from the pickup datetime field. This will create new fields for the month number, day of month, day of week, and hour of day, and will allow the model to factor in time-based seasonality. \n",
    "\n",
    "Use the `apply()` function on the dataframe to iteratively apply the `build_time_features()` function to each row in the taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>lpepPickupDatetime</th>\n",
       "      <th>lpepDropoffDatetime</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>puLocationId</th>\n",
       "      <th>doLocationId</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>...</th>\n",
       "      <th>tipAmount</th>\n",
       "      <th>tollsAmount</th>\n",
       "      <th>ehailFee</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>tripType</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "      <td>2015-01-30 19:01:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.996155</td>\n",
       "      <td>40.690903</td>\n",
       "      <td>-73.964287</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "      <td>2015-01-17 23:35:16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.687984</td>\n",
       "      <td>-73.955116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "      <td>2015-01-16 01:52:55</td>\n",
       "      <td>1</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.957787</td>\n",
       "      <td>40.721779</td>\n",
       "      <td>-73.963005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "      <td>2015-01-04 17:16:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.919914</td>\n",
       "      <td>40.826023</td>\n",
       "      <td>-73.904839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "      <td>2015-01-14 10:33:30</td>\n",
       "      <td>1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.943710</td>\n",
       "      <td>40.825439</td>\n",
       "      <td>-73.982964</td>\n",
       "      <td>...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-19 18:10:41</td>\n",
       "      <td>2015-01-19 18:32:20</td>\n",
       "      <td>1</td>\n",
       "      <td>7.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.940918</td>\n",
       "      <td>40.839714</td>\n",
       "      <td>-73.994339</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-19 18:10:41</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01 15:44:21</td>\n",
       "      <td>2015-01-01 15:50:16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985718</td>\n",
       "      <td>40.685646</td>\n",
       "      <td>-73.996773</td>\n",
       "      <td>...</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-01 15:44:21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-12 08:01:21</td>\n",
       "      <td>2015-01-12 08:14:52</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.939865</td>\n",
       "      <td>40.789822</td>\n",
       "      <td>-73.952957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-12 08:01:21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-16 21:54:26</td>\n",
       "      <td>2015-01-16 22:12:39</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.957939</td>\n",
       "      <td>40.721928</td>\n",
       "      <td>-73.926247</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-16 21:54:26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06 06:34:53</td>\n",
       "      <td>2015-01-06 06:44:23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.943825</td>\n",
       "      <td>40.810257</td>\n",
       "      <td>-73.943062</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-06 06:34:53</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorID  lpepPickupDatetime lpepDropoffDatetime  passengerCount  \\\n",
       "0         2 2015-01-30 18:38:09 2015-01-30 19:01:49               1   \n",
       "1         1 2015-01-17 23:21:39 2015-01-17 23:35:16               1   \n",
       "2         2 2015-01-16 01:38:40 2015-01-16 01:52:55               1   \n",
       "3         2 2015-01-04 17:09:26 2015-01-04 17:16:12               1   \n",
       "4         1 2015-01-14 10:10:57 2015-01-14 10:33:30               1   \n",
       "5         2 2015-01-19 18:10:41 2015-01-19 18:32:20               1   \n",
       "6         2 2015-01-01 15:44:21 2015-01-01 15:50:16               1   \n",
       "7         2 2015-01-12 08:01:21 2015-01-12 08:14:52               5   \n",
       "8         1 2015-01-16 21:54:26 2015-01-16 22:12:39               1   \n",
       "9         2 2015-01-06 06:34:53 2015-01-06 06:44:23               1   \n",
       "\n",
       "   tripDistance  puLocationId  doLocationId  pickupLongitude  pickupLatitude  \\\n",
       "0          1.88           NaN           NaN       -73.996155       40.690903   \n",
       "1          2.70           NaN           NaN       -73.978508       40.687984   \n",
       "2          3.54           NaN           NaN       -73.957787       40.721779   \n",
       "3          1.00           NaN           NaN       -73.919914       40.826023   \n",
       "4          5.10           NaN           NaN       -73.943710       40.825439   \n",
       "5          7.41           NaN           NaN       -73.940918       40.839714   \n",
       "6          1.03           NaN           NaN       -73.985718       40.685646   \n",
       "7          2.94           NaN           NaN       -73.939865       40.789822   \n",
       "8          3.00           NaN           NaN       -73.957939       40.721928   \n",
       "9          2.31           NaN           NaN       -73.943825       40.810257   \n",
       "\n",
       "   dropoffLongitude  ...  tipAmount  tollsAmount ehailFee  totalAmount  \\\n",
       "0        -73.964287  ...       4.00          0.0      NaN        20.80   \n",
       "1        -73.955116  ...       2.55          0.0      NaN        15.35   \n",
       "2        -73.963005  ...       2.80          0.0      NaN        17.60   \n",
       "3        -73.904839  ...       0.00          0.0      NaN         7.30   \n",
       "4        -73.982964  ...       3.85          0.0      NaN        23.15   \n",
       "5        -73.994339  ...       4.80          0.0      NaN        29.60   \n",
       "6        -73.996773  ...       1.30          0.0      NaN         8.60   \n",
       "7        -73.952957  ...       0.00          0.0      NaN        13.30   \n",
       "8        -73.926247  ...       2.00          0.0      NaN        17.30   \n",
       "9        -73.943062  ...       2.00          0.0      NaN        12.80   \n",
       "\n",
       "   tripType   __index_level_0__  month_num day_of_month  day_of_week  \\\n",
       "0       1.0 2015-01-30 18:38:09          1           30            4   \n",
       "1       1.0 2015-01-17 23:21:39          1           17            5   \n",
       "2       1.0 2015-01-16 01:38:40          1           16            4   \n",
       "3       1.0 2015-01-04 17:09:26          1            4            6   \n",
       "4       1.0 2015-01-14 10:10:57          1           14            2   \n",
       "5       1.0 2015-01-19 18:10:41          1           19            0   \n",
       "6       1.0 2015-01-01 15:44:21          1            1            3   \n",
       "7       1.0 2015-01-12 08:01:21          1           12            0   \n",
       "8       1.0 2015-01-16 21:54:26          1           16            4   \n",
       "9       1.0 2015-01-06 06:34:53          1            6            1   \n",
       "\n",
       "   hour_of_day  \n",
       "0           18  \n",
       "1           23  \n",
       "2            1  \n",
       "3           17  \n",
       "4           10  \n",
       "5           18  \n",
       "6           15  \n",
       "7            8  \n",
       "8           21  \n",
       "9            6  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_time_features(vector):\n",
    "    pickup_datetime = vector[0]\n",
    "    month_num = pickup_datetime.month\n",
    "    day_of_month = pickup_datetime.day\n",
    "    day_of_week = pickup_datetime.weekday()\n",
    "    hour_of_day = pickup_datetime.hour\n",
    "    \n",
    "    return pd.Series((month_num, day_of_month, day_of_week, hour_of_day))\n",
    "\n",
    "green_taxi_df[[\"month_num\", \"day_of_month\",\"day_of_week\", \"hour_of_day\"]] = green_taxi_df[[\"lpepPickupDatetime\"]].apply(build_time_features, axis=1)\n",
    "green_taxi_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some of the columns that you won't need for training or additional feature building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>dropoffLatitude</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-73.996155</td>\n",
       "      <td>40.690903</td>\n",
       "      <td>-73.964287</td>\n",
       "      <td>40.679707</td>\n",
       "      <td>20.80</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>-73.978508</td>\n",
       "      <td>40.687984</td>\n",
       "      <td>-73.955116</td>\n",
       "      <td>40.708138</td>\n",
       "      <td>15.35</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.54</td>\n",
       "      <td>-73.957787</td>\n",
       "      <td>40.721779</td>\n",
       "      <td>-73.963005</td>\n",
       "      <td>40.682774</td>\n",
       "      <td>17.60</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-73.919914</td>\n",
       "      <td>40.826023</td>\n",
       "      <td>-73.904839</td>\n",
       "      <td>40.821404</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>-73.943710</td>\n",
       "      <td>40.825439</td>\n",
       "      <td>-73.982964</td>\n",
       "      <td>40.767857</td>\n",
       "      <td>23.15</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorID  passengerCount  tripDistance  pickupLongitude  pickupLatitude  \\\n",
       "0         2               1          1.88       -73.996155       40.690903   \n",
       "1         1               1          2.70       -73.978508       40.687984   \n",
       "2         2               1          3.54       -73.957787       40.721779   \n",
       "3         2               1          1.00       -73.919914       40.826023   \n",
       "4         1               1          5.10       -73.943710       40.825439   \n",
       "\n",
       "   dropoffLongitude  dropoffLatitude  totalAmount   __index_level_0__  \\\n",
       "0        -73.964287        40.679707        20.80 2015-01-30 18:38:09   \n",
       "1        -73.955116        40.708138        15.35 2015-01-17 23:21:39   \n",
       "2        -73.963005        40.682774        17.60 2015-01-16 01:38:40   \n",
       "3        -73.904839        40.821404         7.30 2015-01-04 17:09:26   \n",
       "4        -73.982964        40.767857        23.15 2015-01-14 10:10:57   \n",
       "\n",
       "   month_num  day_of_month  day_of_week  hour_of_day  \n",
       "0          1            30            4           18  \n",
       "1          1            17            5           23  \n",
       "2          1            16            4            1  \n",
       "3          1             4            6           17  \n",
       "4          1            14            2           10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = [\"lpepPickupDatetime\", \"lpepDropoffDatetime\", \"puLocationId\", \"doLocationId\", \"extra\", \"mtaTax\",\n",
    "                     \"improvementSurcharge\", \"tollsAmount\", \"ehailFee\", \"tripType\", \"rateCodeID\", \n",
    "                     \"storeAndFwdFlag\", \"paymentType\", \"fareAmount\", \"tipAmount\"\n",
    "                    ]\n",
    "for col in columns_to_remove:\n",
    "    green_taxi_df.pop(col)\n",
    "    \n",
    "green_taxi_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanse data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `describe()` function on the new dataframe to see summary statistics for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>dropoffLatitude</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.777625</td>\n",
       "      <td>1.373625</td>\n",
       "      <td>2.893981</td>\n",
       "      <td>-73.827403</td>\n",
       "      <td>40.689730</td>\n",
       "      <td>-73.819670</td>\n",
       "      <td>40.684436</td>\n",
       "      <td>14.892744</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.150208</td>\n",
       "      <td>3.266042</td>\n",
       "      <td>13.623458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.415850</td>\n",
       "      <td>1.046180</td>\n",
       "      <td>3.072343</td>\n",
       "      <td>2.821767</td>\n",
       "      <td>1.556082</td>\n",
       "      <td>2.901199</td>\n",
       "      <td>1.599776</td>\n",
       "      <td>12.339749</td>\n",
       "      <td>3.452124</td>\n",
       "      <td>8.432627</td>\n",
       "      <td>1.965772</td>\n",
       "      <td>6.818732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.357101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.342766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-120.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>-73.959175</td>\n",
       "      <td>40.699127</td>\n",
       "      <td>-73.966476</td>\n",
       "      <td>40.699459</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>-73.945049</td>\n",
       "      <td>40.746754</td>\n",
       "      <td>-73.944221</td>\n",
       "      <td>40.747536</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-73.917089</td>\n",
       "      <td>40.803060</td>\n",
       "      <td>-73.909061</td>\n",
       "      <td>40.791526</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>154.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.109089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.982826</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendorID  passengerCount  tripDistance  pickupLongitude  \\\n",
       "count  24000.000000    24000.000000  24000.000000     24000.000000   \n",
       "mean       1.777625        1.373625      2.893981       -73.827403   \n",
       "std        0.415850        1.046180      3.072343         2.821767   \n",
       "min        1.000000        0.000000      0.000000       -74.357101   \n",
       "25%        2.000000        1.000000      1.050000       -73.959175   \n",
       "50%        2.000000        1.000000      1.930000       -73.945049   \n",
       "75%        2.000000        1.000000      3.700000       -73.917089   \n",
       "max        2.000000        8.000000    154.280000         0.000000   \n",
       "\n",
       "       pickupLatitude  dropoffLongitude  dropoffLatitude   totalAmount  \\\n",
       "count    24000.000000      24000.000000     24000.000000  24000.000000   \n",
       "mean        40.689730        -73.819670        40.684436     14.892744   \n",
       "std          1.556082          2.901199         1.599776     12.339749   \n",
       "min          0.000000        -74.342766         0.000000   -120.800000   \n",
       "25%         40.699127        -73.966476        40.699459      8.000000   \n",
       "50%         40.746754        -73.944221        40.747536     11.300000   \n",
       "75%         40.803060        -73.909061        40.791526     17.800000   \n",
       "max         41.109089          0.000000        40.982826    425.000000   \n",
       "\n",
       "          month_num  day_of_month   day_of_week   hour_of_day  \n",
       "count  24000.000000  24000.000000  24000.000000  24000.000000  \n",
       "mean       6.500000     15.150208      3.266042     13.623458  \n",
       "std        3.452124      8.432627      1.965772      6.818732  \n",
       "min        1.000000      1.000000      0.000000      0.000000  \n",
       "25%        3.750000      8.000000      2.000000      9.000000  \n",
       "50%        6.500000     15.000000      3.000000     15.000000  \n",
       "75%        9.250000     22.000000      5.000000     19.000000  \n",
       "max       12.000000     30.000000      6.000000     23.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_taxi_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary statistics, you see that there are several fields that have outliers or values that will reduce model accuracy. First filter the lat/long fields to be within the bounds of the Manhattan area. This will filter out longer taxi trips or trips that are outliers in respect to their relationship with other features. \n",
    "\n",
    "Additionally filter the `tripDistance` field to be greater than zero but less than 31 miles (the haversine distance between the two lat/long pairs). This eliminates long outlier trips that have inconsistent trip cost.\n",
    "\n",
    "Lastly, the `totalAmount` field has negative values for the taxi fares, which don't make sense in the context of our model, and the `passengerCount` field has bad data with the minimum values being zero.\n",
    "\n",
    "Filter out these anomalies using query functions, and then remove the last few columns unnecessary for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = green_taxi_df.query(\"pickupLatitude>=40.53 and pickupLatitude<=40.88\")\n",
    "final_df = final_df.query(\"pickupLongitude>=-74.09 and pickupLongitude<=-73.72\")\n",
    "final_df = final_df.query(\"tripDistance>=0.25 and tripDistance<31\")\n",
    " = final_df.query(\"passengerCount>0 and totalAmount>0\")\n",
    "\n",
    "columns_to_remove_for_training = [\"pickupLongitude\", \"pickupLatitude\", \"dropoffLongitude\", \"dropoffLatitude\"]\n",
    "for col in columns_to_remove_for_training:\n",
    "    final_df.pop(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `describe()` again on the data to ensure cleansing worked as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "      <td>23222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.778572</td>\n",
       "      <td>1.374688</td>\n",
       "      <td>2.956753</td>\n",
       "      <td>14.838994</td>\n",
       "      <td>6.502541</td>\n",
       "      <td>15.139437</td>\n",
       "      <td>3.274524</td>\n",
       "      <td>13.635087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.415217</td>\n",
       "      <td>1.046995</td>\n",
       "      <td>2.862415</td>\n",
       "      <td>10.363600</td>\n",
       "      <td>3.453589</td>\n",
       "      <td>8.425423</td>\n",
       "      <td>1.964555</td>\n",
       "      <td>6.822877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>17.880000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.840000</td>\n",
       "      <td>191.700000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendorID  passengerCount  tripDistance   totalAmount     month_num  \\\n",
       "count  23222.000000    23222.000000  23222.000000  23222.000000  23222.000000   \n",
       "mean       1.778572        1.374688      2.956753     14.838994      6.502541   \n",
       "std        0.415217        1.046995      2.862415     10.363600      3.453589   \n",
       "min        1.000000        1.000000      0.250000      0.010000      1.000000   \n",
       "25%        2.000000        1.000000      1.100000      8.190000      4.000000   \n",
       "50%        2.000000        1.000000      2.000000     11.750000      7.000000   \n",
       "75%        2.000000        1.000000      3.760000     17.880000     10.000000   \n",
       "max        2.000000        8.000000     30.840000    191.700000     12.000000   \n",
       "\n",
       "       day_of_month   day_of_week   hour_of_day  \n",
       "count  23222.000000  23222.000000  23222.000000  \n",
       "mean      15.139437      3.274524     13.635087  \n",
       "std        8.425423      1.964555      6.822877  \n",
       "min        1.000000      0.000000      0.000000  \n",
       "25%        8.000000      2.000000      9.000000  \n",
       "50%       15.000000      3.000000     15.000000  \n",
       "75%       22.000000      5.000000     19.000000  \n",
       "max       30.000000      6.000000     23.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a workspace object from the existing workspace. A [Workspace](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py) is a class that accepts your Azure subscription and resource information. It also creates a cloud resource to monitor and track your model runs. `Workspace.from_config()` reads the file **config.json** and loads the authentication details into an object named `ws`. `ws` is used throughout the rest of the code in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='mm-machine-learning-ws-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-rg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will save into a register folder the data set that we are going to register for later use. Notice that we have now created a new folder that holds the dataset we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-python-version/code/Users/memasanz/regression-automl-nyc-taxi-data\n",
      "memasanz-ds-prepped.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os. getcwd()\n",
    "print(cwd)\n",
    "dataset_name = user + '-ds-prepped.csv'\n",
    "print(dataset_name)\n",
    "dataset_dir = './register/'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "file_path = os.path.join(dataset_dir, dataset_name)\n",
    "final_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file to the datastore from the register folder to data/prepped folder\n",
    "\n",
    "upload(src_dir, target_path=None, overwrite=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading register/ds-prepped.csv\n",
      "Uploaded register/ds-prepped.csv, 1 files out of an estimated total of 3\n",
      "Uploading register/memasanz-ds-prepped.csv\n",
      "Uploaded register/memasanz-ds-prepped.csv, 2 files out of an estimated total of 3\n",
      "Uploading register/memasanzds-prepped.csv\n",
      "Uploaded register/memasanzds-prepped.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'data/prepped/memasanz-ds-prepped.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"371b1cc7-a9f6-4b10-86fc-4ba8538b8c65\",\n",
       "    \"name\": \"memasanz-ds-prepped.csv\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='mm-machine-learning-ws-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-rg')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "ds = Datastore.get_default(ws)\n",
    "ds.upload('register/', target_path='data/prepped', overwrite=True)\n",
    "\n",
    "from azureml.core.dataset import Dataset\n",
    "#create a dataset object from the uploaded file\n",
    "#prepped_dataset = Dataset.File.from_files((ds, 'data/prepped'))\n",
    "dataset = Dataset.Tabular.from_delimited_files(ds.path('data/prepped/' + dataset_name))\n",
    "#register dataset\n",
    "dataset.register(ws, dataset_name, create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>month_num</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.88</td>\n",
       "      <td>20.80</td>\n",
       "      <td>2015-01-30 18:38:09</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>15.35</td>\n",
       "      <td>2015-01-17 23:21:39</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.54</td>\n",
       "      <td>17.60</td>\n",
       "      <td>2015-01-16 01:38:40</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2015-01-04 17:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>23.15</td>\n",
       "      <td>2015-01-14 10:10:57</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>5.30</td>\n",
       "      <td>2015-12-21 20:36:02</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2015-12-16 17:48:50</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>11.16</td>\n",
       "      <td>2015-12-22 22:47:05</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>17.75</td>\n",
       "      <td>2015-12-20 08:24:12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23221</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>20.15</td>\n",
       "      <td>2015-12-14 05:02:13</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vendorID  passengerCount  tripDistance  totalAmount  \\\n",
       "0             2               1          1.88        20.80   \n",
       "1             1               1          2.70        15.35   \n",
       "2             2               1          3.54        17.60   \n",
       "3             2               1          1.00         7.30   \n",
       "4             1               1          5.10        23.15   \n",
       "...         ...             ...           ...          ...   \n",
       "23217         2               1          0.42         5.30   \n",
       "23218         2               1          0.32         5.80   \n",
       "23219         2               1          1.80        11.16   \n",
       "23220         1               1          4.00        17.75   \n",
       "23221         1               1          3.80        20.15   \n",
       "\n",
       "        __index_level_0__  month_num  day_of_month  day_of_week  hour_of_day  \n",
       "0     2015-01-30 18:38:09          1            30            4           18  \n",
       "1     2015-01-17 23:21:39          1            17            5           23  \n",
       "2     2015-01-16 01:38:40          1            16            4            1  \n",
       "3     2015-01-04 17:09:26          1             4            6           17  \n",
       "4     2015-01-14 10:10:57          1            14            2           10  \n",
       "...                   ...        ...           ...          ...          ...  \n",
       "23217 2015-12-21 20:36:02         12            21            0           20  \n",
       "23218 2015-12-16 17:48:50         12            16            2           17  \n",
       "23219 2015-12-22 22:47:05         12            22            1           22  \n",
       "23220 2015-12-20 08:24:12         12            20            6            8  \n",
       "23221 2015-12-14 05:02:13         12            14            0            5  \n",
       "\n",
       "[23222 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of consuming the dataset.\n",
    "\n",
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '5da07161-3770-4a4b-aa43-418cbbb627cf'\n",
    "resource_group = 'mm-machine-learning-rg'\n",
    "workspace_name = 'mm-machine-learning-ws-dev'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name=dataset_name)\n",
    "dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the automatic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an experiment object in your workspace. An experiment acts as a container for your individual runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, user + \"python-regression-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-python-version/code/Users/memasanz/regression-automl-nyc-taxi-data/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"train\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: ADD PARAMETER FOR DATASET NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-python-version/code/Users/memasanz/regression-automl-nyc-taxi-data/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.run import Run\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Workspace\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data-path', type=str)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = getRuntimeArgs()\n",
    "    run = Run.get_context()\n",
    "\n",
    "    \n",
    "    dataset_dir = './dataset/'\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    ws = run.experiment.workspace\n",
    "    print(ws)\n",
    "\n",
    "    dataset_lt = Dataset.get_by_name(ws, name='memasanz-ds-prepped.csv')\n",
    "    \n",
    "    # Load a TabularDataset & save into pandas DataFrame\n",
    "    df = dataset_lt.to_pandas_dataframe()\n",
    "    df.to_csv(os.path.join(dataset_dir, 'dataset.csv'), index = False)\n",
    "    \n",
    "\n",
    "    lr = model_train(df, run)\n",
    "\n",
    "    #copying to \"outputs\" directory, automatically uploads it to Azure ML\n",
    "    output_dir = './outputs/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    joblib.dump(value=lr, filename=os.path.join(output_dir, 'model.pkl'))\n",
    "\n",
    "def model_train(ds_df, run):\n",
    "\n",
    "    y_raw = ds_df['totalAmount']\n",
    "    X_raw = ds_df.drop('totalAmount', axis=1)\n",
    "\n",
    "    categorical_features = X_raw.select_dtypes(include=['object']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['int64', 'float']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=\"missing\")),('onehotencoder', OneHotEncoder(categories='auto', sparse=False))])\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "    feature_engineering_pipeline = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ], remainder=\"drop\")\n",
    "\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "    clf = Pipeline(steps=[('preprocessor', feature_engineering_pipeline),('regr', LinearRegression())])\n",
    "    clf.fit(X_train, y_train)\n",
    "    #\n",
    "\n",
    "\n",
    "    # Capture metrics\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    print(\"Training accuracy: %.3f\" % train_acc)\n",
    "    print(\"Test data accuracy: %.3f\" % test_acc)\n",
    "\n",
    "    # Log to Azure ML\n",
    "    run.log('Train accuracy', train_acc)\n",
    "    run.log('Test accuracy', test_acc)\n",
    "\n",
    "    return clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memasanz\n",
      "memasanz-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "print(user)\n",
    "compute_name = user + \"-cluster\"\n",
    "print(compute_name)\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13\",\n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "dependencies = CondaDependencies()\n",
    "dependencies.add_pip_package('numpy==1.17.0')\n",
    "dependencies.add_pip_package('joblib==0.14.1')\n",
    "dependencies.add_pip_package('scikit-learn')\n",
    "\n",
    "#     - numpy==1.16.2\n",
    "#     - scikit-learn==0.20.3\n",
    "#     - scipy==1.2.1\n",
    "#     - pandas==0.25.3\n",
    "#     - joblib==0.13.2\n",
    "\n",
    "#Create a Run Configuration and add this to your pythonscriptstep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "run_config = RunConfiguration()\n",
    "run_config.target = compute_name\n",
    "run_config.environment.python.conda_dependencies = dependencies\n",
    "run_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your training script and create a ScriptRunConfig\n",
    "A ScriptRunConfig object packages together the environment from a RunConfiguration along with your model training script. This object can then be submitted to your experiment and model training will commence on your remote cluster. \n",
    "\n",
    "In this sample, we have put the training script in a separate directory which is targeted for training. This separation allows for a snapshot of just the relevant pieces of code to be stored with the Run in your AML workspace. The <code>train.py</code> file here accesses your registered datasets, trains a model, saves a pickled version, and registers the trained model.\n",
    "\n",
    "ScriptRunConfiguration documentation: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory='./train', script='train.py')\n",
    "src.run_config = run_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the training run\n",
    "Here, the ScriptRunConfiguration is submitted as a run which triggers your model training operation. The cluster you defined above is automatically spun up and the training procedures outlined in ./train/train.py begin. That file contains all the code needed to train and save a pickled version of your trained model. The code below will display the output logs from your training job - you can also monitor training progress inside AML studio.\n",
    "\n",
    "Note: As you iterate on your model, you should modify the code inside ./train/train.py. The model parameters there were adjusted for rapid training and should not be used for a production scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00fbf8efcae4a2ca3b950bd8d09f807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/memasanzpython-regression-taxi-experiment/runs/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-rg/workspaces/mm-machine-learning-ws-dev\", \"run_id\": \"memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\", \"run_properties\": {\"run_id\": \"memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\", \"created_utc\": \"2020-10-13T19:05:09.542198Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"315c3960-1602-4d9a-b8ad-e456c8ba637f\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-10-13T19:15:25.18759Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=Y21PiIy4qCUU6OCv95uDnOqKqRfwS1I7esi%2FiGEcVYE%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=P7%2B4RdJEsG4HKdj5rTakl3gA2K7byJzWpvTUaCGrNn8%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/65_job_prep-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=gTt2%2BSL7PGU4%2BzY2SJQ2vL9K3rkaEay6eAvZMSm3Bc4%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=4CD8K2J15%2FqX6A8xD8s%2Fz4QJ4pwWO3NmhvsAbBqQ%2B4E%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=1t5%2FwnpyHT4P7AucYsJg28spN42A08CcGiDa6OX2GVk%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=th0G6rq%2BJAXi665qnAFweTC84%2BiFUB%2B87sdXO4XjiEg%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=vKefw94oLxfMjXttUeM3y30s%2FNbako31hHnIhoSqnEc%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/132_azureml.log\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/132_azureml.log?sv=2019-02-02&sr=b&sig=AUmZThQx5h1QliAec0TmENuRUbRdUgIkDn5oJ4%2FGojI%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=QLa17bDp%2FL6A0Cayv6RSfkPdp7juA7vjkyEwpQbibtE%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=dWRsB6xjlto3Tf4kQjhLUBnMSglLvjvukRaB%2FBpd3b4%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/dataprep/engine_spans_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/engine_spans_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl?sv=2019-02-02&sr=b&sig=0LvlWkiU0YVjou1ZTdXFJzSVfCXPypxWgfo9nXc4SYI%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/dataprep/python_span_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/python_span_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl?sv=2019-02-02&sr=b&sig=GjrGQB9U%2Bu2xqUR1xXb9AaP5KiyK3m1h88d08oBkRwE%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2FuH5SwTxSq2v7g07s3hGljaIrIFt%2BT7eeL3yufj24gw%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=9B54R9DnMu%2F692Oq4nnwfUzhXeQ9HCoSlBQDp0bEoUA%3D&st=2020-10-14T12%3A16%3A14Z&se=2020-10-14T20%3A26%3A14Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/dataprep/engine_spans_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl\", \"logs/azureml/dataprep/python_span_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\"], [\"logs/azureml/132_azureml.log\"]], \"run_duration\": \"0:10:15\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Train accuracy\", \"run_id\": \"memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\", \"categories\": [0], \"series\": [{\"data\": [0.8577399618717584]}]}, {\"name\": \"Test accuracy\", \"run_id\": \"memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\", \"categories\": [0], \"series\": [{\"data\": [0.8905551665244333]}]}], \"run_logs\": \"2020-10-13 19:14:32,036|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-10-13 19:14:32,037|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-10-13 19:14:32,043|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-10-13 19:14:32,043|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-10-13 19:14:32,344|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f40710f2a60> for run source azureml.scriptrun\\n2020-10-13 19:14:32,372|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 19:14:32,380|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-10-13 19:14:32,380|azureml.core.authentication|DEBUG|Time to expire 1813836.619171 seconds\\n2020-10-13 19:14:32,381|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2020-10-13 19:14:32,381|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,381|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,381|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,381|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,381|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2020-10-13 19:14:32,473|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,473|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,474|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:32,526|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-10-13 19:14:32,526|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}\\n2020-10-13 19:14:32,984|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-10-13 19:14:32,984|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '315c3960-1602-4d9a-b8ad-e456c8ba637f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-10-13 19:14:32,985|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-10-13 19:14:32,985|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-10-13 19:14:32,985|azureml.WorkerPool|DEBUG|[START]\\n2020-10-13 19:14:32,985|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-10-13 19:14:32,985|azureml.RunStatusContext|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml.MetricsClient|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-10-13 19:14:32,986|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\\n2020-10-13 19:14:32,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-10-13 19:14:32,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\\n2020-10-13 19:14:36,450|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,480|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-10-13 19:14:36,480|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}\\n2020-10-13 19:14:36,576|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-10-13 19:14:36,577|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '315c3960-1602-4d9a-b8ad-e456c8ba637f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-10-13 19:14:36,577|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-10-13 19:14:36,604|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,604|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,605|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,605|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,605|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,605|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,606|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,852|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,854|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,854|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,861|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,861|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,862|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,862|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,862|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,862|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,862|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,863|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,869|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,869|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,869|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,869|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,869|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,870|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,870|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,870|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,876|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,877|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,878|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,884|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.patch-async:False|DEBUG|[START]\\n2020-10-13 19:14:36,884|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}\\n2020-10-13 19:14:36,989|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.RunClient.patch-async:False|DEBUG|[STOP]\\n2020-10-13 19:14:36,989|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,990|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,991|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,998|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:36,998|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,998|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,998|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,998|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,999|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,999|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:36,999|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,494|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,494|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,494|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,494|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,494|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,495|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,495|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,495|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,503|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,503|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,503|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,504|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,504|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,504|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,504|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,504|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,511|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,511|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,511|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,511|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,512|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,512|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,512|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,512|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,519|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,519|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,519|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,519|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,527|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,528|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,528|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,528|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,672|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,672|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,672|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,673|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,673|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,673|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,673|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,673|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,703|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-10-13 19:14:51,703|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,704|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,704|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,704|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,705|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,705|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:51,705|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2020-10-13 19:14:53,720|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 19:14:53,720|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 19:14:53,725|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 19:14:54,669|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-10-13 19:14:54,669|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\\n2020-10-13 19:14:54,669|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a to /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\\n2020-10-13 19:14:54,669|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\\n2020-10-13 19:14:54,670|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-10-13 19:14:54,670|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-10-13 19:14:54,670|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 19:14:54,670|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 19:14:54,670|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 19:14:54,671|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 19:14:54,672|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 19:14:54,725|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-10-13 19:14:54,726|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-10-13 19:14:54,726|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 2.\\n2020-10-13 19:14:54,726|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-10-13 19:14:54,726|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-10-13 19:14:54,727|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-10-13 19:14:54,727|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 2 values.\\n2020-10-13 19:14:54,727|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-10-13 19:14:54,727|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-10-13 19:14:54,727|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-10-13 19:14:54,727|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-10-13 19:14:54,728|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-10-13 19:14:54,728|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-10-13 19:14:54,728|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-10-13 19:14:54,732|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-10-13 19:14:54,733|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-10-13 19:14:54,733|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-10-13 19:14:54,733|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-10-13 19:14:54,733|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-10-13 19:14:54,733|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-10-13 19:14:54,944|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-10-13 19:14:55,496|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 19:15:00,498|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2020-10-13 19:15:00,594|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,595|azureml.MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,595|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 19:15:00,596|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 19:15:00,714|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 19:15:00,714|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 19:15:00,715|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 19:15:00,716|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,716|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,716|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 19:15:00,716|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 19:15:00,800|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 19:15:00,801|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,801|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-10-13 19:15:00,801|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-10-13 19:15:00,802|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-10-13 19:15:00,803|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-10-13 19:15:00,803|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,803|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-10-13 19:15:00,803|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-10-13 19:15:00,803|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-10-13 19:15:01,289|azureml._SubmittedRun#memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-10-13 19:15:01,289|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-10-13 19:15:01,290|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-10-13 19:15:01,290|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-10-13 19:15:01,290|azureml.WorkerPool|DEBUG|[STOP]\\n2020-10-13 19:15:02,375|azureml.core.authentication|DEBUG|Time to expire 1813806.624502 seconds\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.15.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\n",
      "Web View: https://ml.azure.com/experiments/memasanzpython-regression-taxi-experiment/runs/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-rg/workspaces/mm-machine-learning-ws-dev\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2020/10/13 19:05:15 Downloading source code...\n",
      "2020/10/13 19:05:16 Finished downloading source code\n",
      "2020/10/13 19:05:17 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/10/13 19:05:17 Successfully set up Docker network: acb_default_network\n",
      "2020/10/13 19:05:17 Setting up Docker configuration...\n",
      "2020/10/13 19:05:18 Successfully set up Docker configuration\n",
      "2020/10/13 19:05:18 Logging in to registry: 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io\n",
      "2020/10/13 19:05:19 Successfully logged into 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io\n",
      "2020/10/13 19:05:19 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/10/13 19:05:19 Scanning for dependencies...\n",
      "2020/10/13 19:05:19 Successfully scanned dependencies\n",
      "2020/10/13 19:05:19 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "Digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      " ---> 287916b809d9\n",
      "Step 2/15 : USER root\n",
      " ---> Running in b3bd7fdc4779\n",
      "Removing intermediate container b3bd7fdc4779\n",
      " ---> cb76f3570e25\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 7213095ac455\n",
      "Removing intermediate container 7213095ac455\n",
      " ---> 320eb8942022\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 74de0579bf44\n",
      "Removing intermediate container 74de0579bf44\n",
      " ---> 325700b7ec05\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> c566c5069a39\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in d75d91bc854f\n",
      "Removing intermediate container d75d91bc854f\n",
      " ---> 7ecdad5f6efb\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 1dbcdf67896a\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 461cddd104a4\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ###        |  31% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | #######8   |  78% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #####      |  50% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "pip-20.2.3           | 2.0 MB    |            |   0% \n",
      "pip-20.2.3           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | ##1        |  21% \n",
      "python-3.6.2         | 27.0 MB   | ######1    |  61% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.v_wj_wjc.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.16.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting numpy==1.17.0\n",
      "  Downloading numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4 MB)\n",
      "Collecting joblib==0.14.1\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.16.0\n",
      "  Downloading azureml_dataset_runtime-1.16.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-core~=1.16.0\n",
      "  Downloading azureml_core-1.16.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.3-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting six>=1.10\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting azureml-dataprep<2.4.0a,>=2.3.0a\n",
      "  Downloading azureml_dataprep-2.3.2-py3-none-any.whl (28.2 MB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.1.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting pyopenssl<20.0.0\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.2.0-py2.py3-none-any.whl (968 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.v_wj_wjc.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.17-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting azureml-dataprep-native<24.0.0,>=23.0.0\n",
      "  Downloading azureml_dataprep_native-23.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting azure-identity<2.0.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.2.0a,>=1.1.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (7.9 MB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.3-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.8.2-py2.py3-none-any.whl (122 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.5.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.3.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: json-logging-py, dill, liac-arff, fusepy\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=070aca6c90adf7ce80223c369538bc2b086bd458209851878a20d44a92f2c544\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=26ac98ae3ba6becca56de72e2c3c21239f9ddc5e79aec65c622f6c5532ae9d2c\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/49/cf/660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=d0c783a3332b3792e14c93b062b6e81bb9a1c632c022f852f648288068b54767\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=4a5b2dc9acd13a8ae8f159a9e7004b87f0cd00261a20ff0cd9f0266e51226edd\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built json-logging-py dill liac-arff fusepy\n",
      "Installing collected packages: pytz, numpy, six, python-dateutil, chardet, urllib3, idna, requests, dill, pycparser, cffi, cryptography, PyJWT, adal, liac-arff, pandas, azureml-model-management-sdk, werkzeug, gunicorn, applicationinsights, cloudpickle, distro, dotnetcore2, azureml-dataprep-native, azure-core, msal, portalocker, msal-extensions, azure-identity, azureml-dataprep-rslex, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime, pathspec, contextlib2, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-common, azure-mgmt-containerregistry, jmespath, zipp, importlib-metadata, jsonpickle, ruamel.yaml.clib, ruamel.yaml, backports.weakref, backports.tempfile, pyopenssl, pyasn1, ndg-httpsclient, jeepney, SecretStorage, azure-mgmt-keyvault, azure-mgmt-authorization, azure-mgmt-resource, azure-mgmt-storage, azure-graphrbac, websocket-client, docker, azureml-core, MarkupSafe, Jinja2, itsdangerous, click, flask, json-logging-py, configparser, azureml-defaults, joblib, scipy, threadpoolctl, scikit-learn\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.8.2 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.2.0 azure-mgmt-storage-11.2.0 azureml-core-1.16.0 azureml-dataprep-2.3.2 azureml-dataprep-native-23.0.0 azureml-dataprep-rslex-1.1.1 azureml-dataset-runtime-1.16.0 azureml-defaults-1.16.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.3 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.1.1 dill-0.3.2 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.17 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-2.0.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.10.0 joblib-0.14.1 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.5.0 msal-1.5.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.17.0 oauthlib-3.1.0 pandas-1.1.3 pathspec-0.8.0 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 scikit-learn-0.23.2 scipy-1.5.2 six-1.15.0 threadpoolctl-2.1.0 urllib3-1.25.10 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.3.0\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.5\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing intermediate container 461cddd104a4\n",
      " ---> 39778bca4100\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5/bin:$PATH\n",
      " ---> Running in e0c665438c34\n",
      "Removing intermediate container e0c665438c34\n",
      " ---> 03063a6b6cef\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5\n",
      " ---> Running in 18d09e03d6e5\n",
      "Removing intermediate container 18d09e03d6e5\n",
      " ---> af83d1a7add0\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in a5d1a04245f1\n",
      "Removing intermediate container a5d1a04245f1\n",
      " ---> 1f797bd45baa\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 61bdd4f95d3a\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 5e36f74525cd\n",
      "Removing intermediate container 5e36f74525cd\n",
      " ---> 564cc847eb4f\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 07c138784a7d\n",
      "Removing intermediate container 07c138784a7d\n",
      " ---> 1761e8c127ca\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in 8006d7b8f482\n",
      "Removing intermediate container 8006d7b8f482\n",
      " ---> 0b8c0616ecda\n",
      "Successfully built 0b8c0616ecda\n",
      "Successfully tagged 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io/azureml/azureml_3f88a70b849d77efc800aec14911e22d:latest\n",
      "2020/10/13 19:07:40 Successfully executed container: acb_step_0\n",
      "2020/10/13 19:07:40 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/10/13 19:07:40 Pushing image: 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io/azureml/azureml_3f88a70b849d77efc800aec14911e22d:latest, attempt 1\n",
      "The push refers to repository [0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io/azureml/azureml_3f88a70b849d77efc800aec14911e22d]\n",
      "c42ccba60374: Preparing\n",
      "97d044dd73b3: Preparing\n",
      "2ac4bd055259: Preparing\n",
      "922405c521ea: Preparing\n",
      "f424abfb9072: Preparing\n",
      "09f145db2411: Preparing\n",
      "13e378616f24: Preparing\n",
      "efc99d952c3d: Preparing\n",
      "9e292a80b88a: Preparing\n",
      "5e1805eb9eb5: Preparing\n",
      "8dab94e6d05c: Preparing\n",
      "2817caf0a082: Preparing\n",
      "aece08fd27fc: Preparing\n",
      "4caea5ef1f0b: Preparing\n",
      "dcc0cc99372e: Preparing\n",
      "87c128261339: Preparing\n",
      "41a253a417e6: Preparing\n",
      "e06660e80cf4: Preparing\n",
      "5e1805eb9eb5: Waiting\n",
      "8dab94e6d05c: Waiting\n",
      "2817caf0a082: Waiting\n",
      "aece08fd27fc: Waiting\n",
      "4caea5ef1f0b: Waiting\n",
      "dcc0cc99372e: Waiting\n",
      "87c128261339: Waiting\n",
      "41a253a417e6: Waiting\n",
      "e06660e80cf4: Waiting\n",
      "09f145db2411: Waiting\n",
      "13e378616f24: Waiting\n",
      "efc99d952c3d: Waiting\n",
      "9e292a80b88a: Waiting\n",
      "c42ccba60374: Pushed\n",
      "2ac4bd055259: Pushed\n",
      "922405c521ea: Pushed\n",
      "f424abfb9072: Pushed\n",
      "09f145db2411: Pushed\n",
      "13e378616f24: Pushed\n",
      "efc99d952c3d: Pushed\n",
      "9e292a80b88a: Pushed\n",
      "aece08fd27fc: Pushed\n",
      "2817caf0a082: Pushed\n",
      "5e1805eb9eb5: Pushed\n",
      "dcc0cc99372e: Pushed\n",
      "87c128261339: Pushed\n",
      "41a253a417e6: Pushed\n",
      "8dab94e6d05c: Pushed\n",
      "\n",
      "e06660e80cf4: Pushed\n",
      "4caea5ef1f0b: Pushed\n",
      "97d044dd73b3: Pushed\n",
      "latest: digest: sha256:549176a219c4039a7ad3bb417fe5d5c8a78094912cdd171b665ebcc63067ae24 size: 4095\n",
      "2020/10/13 19:09:15 Successfully pushed image: 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io/azureml/azureml_3f88a70b849d77efc800aec14911e22d:latest\n",
      "2020/10/13 19:09:15 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 141.747345)\n",
      "2020/10/13 19:09:15 Populating digests for step ID: acb_step_0...\n",
      "2020/10/13 19:09:17 Successfully populated digests for step ID: acb_step_0\n",
      "2020/10/13 19:09:17 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 94.657858)\n",
      "2020/10/13 19:09:17 The following dependencies were found:\n",
      "2020/10/13 19:09:17 \n",
      "- image:\n",
      "    registry: 0f5f6637ebe142f38aeb0dd9f78d4097.azurecr.io\n",
      "    repository: azureml/azureml_3f88a70b849d77efc800aec14911e22d\n",
      "    tag: latest\n",
      "    digest: sha256:549176a219c4039a7ad3bb417fe5d5c8a78094912cdd171b665ebcc63067ae24\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20200821.v1\n",
      "    digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "  git: {}\n",
      "\n",
      "Run ID: cha was successful after 4m2s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-10-13T19:13:37Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-10-13T19:13:37Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2020-10-13T19:13:37Z Starting output-watcher...\n",
      "2020-10-13T19:13:37Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_3f88a70b849d77efc800aec14911e22d\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "5ab4c756bdcd: Pulling fs layer\n",
      "89897af8e7e8: Pulling fs layer\n",
      "73eef93b7466: Waiting\n",
      "f5d65e5bdb93: Pulling fs layer\n",
      "0b5e02624d2b: Pulling fs layer\n",
      "d5a54c1fb97f: Waiting\n",
      "e7e11beb1ebf: Pulling fs layer\n",
      "02e09d7fa76b: Pulling fs layer\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "5ab4c756bdcd: Waiting\n",
      "89897af8e7e8: Waiting\n",
      "f5d65e5bdb93: Waiting\n",
      "0b5e02624d2b: Waiting\n",
      "e7e11beb1ebf: Waiting\n",
      "acc000f01536: Download complete\n",
      "73eef93b7466: Verifying Checksum\n",
      "73eef93b7466: Download complete\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "2020/10/13 19:14:27 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2020/10/13 19:14:27 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2020-10-13T19:14:29.396384] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train.py'])\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 132\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/mm-machine-learning-ws-dev/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/mounts/workspaceblobstore/azureml/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\n",
      "Preparing to call script [ train.py ] with arguments: []\n",
      "After variable expansion, calling script [ train.py ] with arguments: []\n",
      "\n",
      "Script type = None\n",
      "Workspace.create(name='mm-machine-learning-ws-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-rg')\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-10-13T19:15:08.249344\n",
      "Starting job release. Current time:2020-10-13T19:15:09.173141\n",
      "Logging experiment finalizing status in history service.\n",
      "[2020-10-13T19:15:09.174050] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 440\n",
      "[{}] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-10-13T19:15:09.174592] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-10-13T19:15:09.182669] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-10-13T19:15:09.182765] job release stage : execute_job_release starting...\n",
      "[2020-10-13T19:15:09.184085] Entering context manager injector.\n",
      "[2020-10-13T19:15:09.185294] job release stage : upload_datastore completed...\n",
      "[2020-10-13T19:15:10.633484] job release stage : send_run_telemetry starting...\n",
      "[2020-10-13T19:15:10.794890] job release stage : execute_job_release completed...\n",
      "[2020-10-13T19:15:14.678942] job release stage : send_run_telemetry completed...\n",
      "Job release is complete. Current time:2020-10-13T19:15:14.679270\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a\n",
      "Web View: https://ml.azure.com/experiments/memasanzpython-regression-taxi-experiment/runs/memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-rg/workspaces/mm-machine-learning-ws-dev\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a',\n",
       " 'target': 'memasanz-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-10-13T19:13:35.561673Z',\n",
       " 'endTimeUtc': '2020-10-13T19:15:25.18759Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '315c3960-1602-4d9a-b8ad-e456c8ba637f',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '371b1cc7-a9f6-4b10-86fc-4ba8538b8c65'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': [],\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'memasanz-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'environment': {'name': 'Experiment memasanzpython-regression-taxi-experiment Environment',\n",
       "   'version': 'Autosave_2020-10-13T19:05:07Z_a9f60975',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'numpy==1.17.0',\n",
       "        'joblib==0.14.1',\n",
       "        'scikit-learn']}],\n",
       "     'name': 'azureml_0f43d1c5aa2e4214a3e1aac40ca0cdb5'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'globalJobDispatcher': {'vmSize': []}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=yRWHUgPybx%2FtVwFChB0O%2BDRhTxsAmCoU3FZNXd4425k%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/55_azureml-execution-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=%2FwAHtHViMZg2IS0d0n5pIF2WU9nfBFQ9h53ionIosp8%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/65_job_prep-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=rhowBWSRew1kEb9dLHN79o2N%2F2%2BTsXth38zCHaRDARU%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=qpq%2BkuREPSHAOz2W1rAWmykmI6n7S8j17ZaXEO7toUU%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/75_job_post-tvmps_649b2b16d905d14d9ae4dc4f39af7face63a7a6fede3c68b1864094082576db5_d.txt?sv=2019-02-02&sr=b&sig=5ofnqmrEN4NKBam4y6AUn4RfRRjvTLWNFzXxPznMRu4%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=HywHpMYp270XTETDLwO2C9PVXqTcazDflohiQbLZJ0w%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=%2B%2BAFsep8SjhjiCNv8ILrRpfBdp4EhBApdqfU4Fs1V%2FI%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/132_azureml.log': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/132_azureml.log?sv=2019-02-02&sr=b&sig=9%2Fp8VrtA9ZoNgie7jnSdJRJXbm%2BcPTILfjOnNhbvbqs%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=MeS%2FesAUTxO%2FsqHqNx52blBT1IxGfIT2IiH2VWs1WiM%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Rp4YOCXNIgHZVEUlYaW%2BycmCDTHxY%2FD0%2B0OkW35acyg%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/engine_spans_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/engine_spans_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl?sv=2019-02-02&sr=b&sig=6XINqSTBGI1rsoOshqj1BhMgabMTNf40tbZktAkRxVA%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/dataprep/python_span_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/dataprep/python_span_l_f9fe7481-c5da-4346-b693-7dd727575d92.jsonl?sv=2019-02-02&sr=b&sig=BAXRiHzyZ4R%2Bomi0YMZQ1GhO9d8EdLWSTNsM9aiamzU%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=Jn3we8Oa9Ar34JiiNoarqqbY54sM5fiWmPD%2FhTkYcuU%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mmmachinelearn6308047299.blob.core.windows.net/azureml/ExperimentRun/dcid.memasanzpython-regression-taxi-experiment_1602615903_fcf15c6a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=KC7Sl5zmXHkTP6%2B29u6CoHCg96uqNRjGvDjYs5AcG8Q%3D&st=2020-10-13T19%3A05%3A29Z&se=2020-10-14T03%3A15%3A29Z&sp=r'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "run = experiment.submit(config=src)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register your model and deploy to an authenticated endpoint\n",
    "Now you have a trained model that has been saved to your run outputs folder. You can register this model and deploy it to an endpoint by defining an inferencing configuration and providing a scoring script. Here the model is deployed to an Azure Container Instance which provides an API endpoint that can be used to make predictions with your LDA model. We utilize an authentication strategy here which requires a key to be provided with any requests sent to the API. These keys can be rotated as needed and allow only approved users to access your endpoint.\n",
    "\n",
    "Azure Container Instances are typically lower cost and useful for dev/test purposes during model development, though we recommend deploying to an Azure Kubernetes Service cluster for production purposes.\n",
    "\n",
    "Below, an InferenceConfig is created which uses the same python dependencies that were used during model training, and references the scoring script located at <code>./score/score.py</code>. This script loads the trained model upon initialization, and facilitates transforming data submitted to the API endpoint, making predictions with the model, and returning formatted results to the user.\n",
    "\n",
    "<b>Note:</b> You should modify this script during development to more appropriately format your model results. \n",
    "\n",
    "Model registration documentation: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where\n",
    "\n",
    "Azure Container Instance documentation: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-container-instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-python-version/code/Users/memasanz/regression-automl-nyc-taxi-data/score\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"score\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-python-version/code/Users/memasanz/regression-automl-nyc-taxi-data/score/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    # Update to your model's filename\n",
    "    model_filename = \"model.pkl\"\n",
    "\n",
    "    # AZUREML_MODEL_DIR is injected by AML\n",
    "    model_dir = os.getenv('AZUREML_MODEL_DIR')\n",
    "\n",
    "    print(\"Model dir:\", model_dir)\n",
    "    print(\"Model filename:\", model_filename)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # Replace this line with your model loading code\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Define some sample data for automatic generation of swagger interface\n",
    "#make\tnum-of-doors\tbody-style\n",
    "input_sample = [{\n",
    " \"vendorID\" : \"1\",\n",
    " \"passengerCount\":1,\n",
    " \"tripDistance\": 4.2,\n",
    " \"month_num\": \"1\",\n",
    " \"day_of_month\" : \"4\",\n",
    " \"day_of_week\" : \"1\",\n",
    " \"hour_of_day\": \"18\"\n",
    "}]\n",
    "output_sample = [18.2281]\n",
    "\n",
    "# This will automatically unmarshall the data parameter in the HTTP request\n",
    "@input_schema('data', StandardPythonParameterType(input_sample))\n",
    "@output_schema(StandardPythonParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        input_df = pd.DataFrame(data)\n",
    "        proba = model.predict(input_df)\n",
    "        \n",
    "        result = {\"predict_proba\": proba.tolist()}\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model_name = user + '-python-regression'\n",
    "trained_model = run.register_model(model_path='outputs/model.pkl', model_name=model_name, tags={'Model Type': 'linear regression'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"tutorial-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-dataprep[pandas,fuse]>=1.1.14\",\n",
       "                        \"azureml-defaults~=1.15.0\",\n",
       "                        \"inference-schema\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn==0.22.1\"\n",
       "            ],\n",
       "            \"name\": \"azureml_cb7e9a7f2d721776fa2112a9ad300910\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"5\"\n",
       "}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataprep[pandas,fuse]>=1.1.14', 'azureml-defaults', 'inference-schema'], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Register environment to re-use later\n",
    "env.register(workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"taxi-prepped\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict taxi pricing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memasanz-python-regression'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running........................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 3.15 s, sys: 289 ms, total: 3.44 s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'memasanz-python-regression')\n",
    "\n",
    "\n",
    "#myenv = Environment.get(workspace=ws, name=\"tutorial-env\", version=\"1\")\n",
    "myenv = Environment.get(workspace=ws, name=\"tutorial-env\", version=\"5\")\n",
    "inference_config = InferenceConfig(source_directory='./score', entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=model_name +'-srv2', \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring API available at: http://d21758e0-bb0a-4b24-abad-5022856ace22.eastus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print('Scoring API available at: {}'.format(service.serialize()['scoringUri']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jeffshep"
   }
  ],
  "categories": [
   "tutorials"
  ],
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "trbye",
  "network_required": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
